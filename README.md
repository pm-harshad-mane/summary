Please welcome Farhan Tower. Hey everyone, my name is Farhan and I want to talk about co-pilot that we use very happily at Shopify. What's interesting about co-pilot is that I want to produce a few guide posts. The reason I want to talk about some guide posts is that in order to get the benefit of co-pilot in your engineering team, you probably have to think much more holistically about your company and AI. What you don't want to have happen is you introduce co-pilot and the rest of your company is not really thinking through its AI strategy. That can mean AI for employees, AI for customers and partners. You do really want to make sure you're getting the benefit of Gen AI everywhere and of course through co-pilot, but I want to walk you through how we got there. We're going to talk about our three things, Shopify Engineering and GitHub, our long-standing partner of GitHub, two, how we think about LLMs and Shopify, and of course the meat everything we do with co-pilot and engineering. First off, let's talk about Shopify. For those who don't know, Shopify is typically the brand behind the brand. We power, I think the world's best D to C sites. Usually if you are outside of Amazon and shopping online and you've had a great experience, it's Shopify. Thomas was actually wearing the same shoes I'm wearing, which are from Vessi, a Shopify merchant. Any time you're actually thinking through how we power all of this, it's actually because of the great work our engineering team and product team and design team build. We power over millions and millions of merchants, all over the world, hundreds and millions of buyers, and PRT messaged me and said, hey, we're almost at a trillion dollars of GMB through the platform. Pretty amazing that we can build together. And just some fast facts, because it's actually interesting when you're powering a platform like this, and again, we use GitHub for all of our workflow that what we can build together. And so the first off is actually we build an amazingly highly converting, beautiful checkout. And it's powered in an ecosystem such that we can do, you know, it sounds like these small numbers, right? 5,000 checkouts submitted, but it auto scales up to eight times that. And what's amazing about that again is we use a lot of automation to enable what we call flash sales. So you can imagine someone like Kim Kardashian dropping a new lipstick or Aloyoga dropping a new color or Taylor Swift dropping some merch. They don't always tell us when they do these things on social media. And so our infrastructure has to automatically scale up to support all of this amazing load. And of course, all throughout with an amazing, beautiful experience such that you get your, what you want to actually get from these vendors. So really, really cool infrastructure. And of course, some stats of there also on just how much we have to support. And just because we're coming into the season, probably the busiest time for internet retail, Black Friday, Cyber Monday. Right? The Thanksgiving, shopping weekend, or week or weeks now, because people tend to have their sales earlier and earlier. And what happens with Shopify is every time we have a Black Friday, Cyber Monday, the internet goes crazy. Our infrastructure goes crazy. And what happens is we set a new baseline for what's possible on the internet. For some of our merchants, when we do a launch, it ends up being the largest sale in internet retail history. And then the next week, it's the largest sale again in internet history. And then the next week, it's the largest sale in internet history. So these things keep going and we set a new baseline. Just an example of what a flash sale looks like, because people tend to get interested in this infrastructure. Kind of like nothing, nothing, nothing. Huge spike in traffic. And then it curls off from that one merchant. So you can imagine this is just one of the millions and millions of merchants on the Shopify platform. Again, scaling up and scaling down. It's pretty nuts. An amazing to see on the infrastructure side. And again, this is what I talk about in terms of setting a new baseline. This is from a few years ago. So every time we have a new Black Friday, Cyber Monday, all over infrastructure ramps up. And then we have this little bit of respite over the December period where it comes down a little bit. But then it actually stays up that high. It's pretty nuts because we end up just literally saying, okay, cool. Black Friday, Cyber Monday of 2021 is now just Tuesday of 2023. Yeah, pretty nuts. I want to talk a little bit about GitHub because of course we are a large GitHub customer who have been for a long time. We have about 4,000 folks in R&D. What's interesting about that is not, it's not only engineers who contribute to GitHub. At Shopify, product managers, UX, data, they're all using GitHub for a lot of their workflow. We have about 300 public repos, right, about 5,000 private repos. It's kind of like a Slack channels, right? There's more of those than there are people in your company. Same with the Shopify, lots of repos. I think we retired or archived 2,000 repos just last week. So we're always trying to make sure that we've got the most effective infrastructure there. Over 10 million lines of code. We joke that we have the, maybe not a joke. We do have the largest Ruby code base in the world, right? And as we try to simplify, maybe that's a good thing or not a good thing as we, you know, try to delete lots of code as well. We do about 1,500 deploys per day. Like I mentioned, over 4,000 contributors and over 100,000 commits per month. Pretty insane and how much we use the GitHub infrastructure to get our work done. So now I want to talk a little bit about LLMs. So in order to then get to where we want to get to, which is empowering and having high productivity range team, I think you really need to think about the entire AI journey of your company. And the first thing that we always think about is making sure that we are bringing LLMs and Gen AI to everyone. Because the panacea is actually having AI to your customers, right? Everybody wants to build something and have AI show up in front of their customers. So you can, whether it's a chatbot, whether it's an experience such that it's magical. You want to make sure that your employees have that experience also at work. And for Shopify that started with our merchants. We launched when ChatGBT came out November 30th, 2022, within two months we had product descriptions. I was actually chatting with the merchant before this, glad and young. And they were talking about how they use this all the time to actually enable very quick product descriptions. So imagine that you are selling soap. And now you have written down all of the interesting aspects of your soap product. You can press a button and magically you can have an SEO friendly, highly playful tone if you want product description. And you can do maybe a dozen of these per day. You can now do hundreds. We actually have the moniker magic that we use for that. So all over the Shopify surface area, you'll see a little magic symbol. And it will allow you to do things. It will allow you to create email subject lines, product headings, all the things that you can imagine that can be magical for your merchants. Again, the reason that we think through this for all of their surfaces is so that we can ensure that our employees are thinking about these tools. So we can actually use our merchants, our merchants, use AI for our help center. Again, we look through all our documentation and allow them to easily search. And we even have something called Sidekick, which you may have heard about two days ago when Sam Altman had it on screen at OpenAI Demo Day. He talked about how we're working with them to build the amazing Sidekick, which is like a co-founder for your business. The second surface that we talk about is our buyers. And again, the first one is Shop AI, which again allows you as a buyer to find a direct-to-d to-see brand that you would love. And of course, again, I talked to this merchant outside, Glad and Young, and then the use the inbox feature, which is basically asking questions from buyers, hey, how do I exchange an item? Do you have this in red? Are there any sales on? And again, all powered by Genai. And I'm not repeating myself. You want to make sure that you are thinking about this in your company because having Genai in just one workflow, likely is not going to succeed. Didn't want to leave our partners and third-party ecosystem out to lunch. We have over 10,000 apps on the ecosystem. And now even our merchants can use AI summaries in their tools to determine whether they want to install one of these apps. But in order to get all of these things, you have to start with your employees. This is where Co-Pilot comes in, but this is where lots of tools come in. We are pretty big adopters of tools. And this is an interesting chart that just showed when the Genai revolution started, again, after ChatGbt, everyone started predicting, where will the productivity come from? Right? If you look at this chart, the first one was sales. We think we can automate sales emails, sales content. The second one was marketing content. And the third one, which surprised me, engineering. Right? Why would engineering be up there? Right? And the idea. And again, we're seeing it with Co-Pilot now, but it was actually a little bit of a puzzle for folks. Why would engineering show up there? What we say to our employees is reach early and often for AI tools. We use these tools very regularly and early, because again, we want to make sure our employees are thinking about this. And what I would tell you, what I tell my parents, is search a reach for an AI tool early and often, because you are not sure what's going to work and what's not going to work. And you can see some of the things we do here, whether it's Co-Pilot, whether it's ChatGbt, or even mid-journey with our design team. Don't even think about Co-Pilot until you've thought about AI for your company. Think I've said it enough. And one of the things we do say is, don't think about AI as a replacement for jobs. Think of it as a replacement for tasks. That is exactly what it's doing. We're not trying to replace engineers. We're trying to replace the tasks that some engineers do. Let's talk about Co-Pilot. This is an email. I sent to Thomas after he got the job in 2021. I highlighted two things here. The first thing is the date. December 2021. This is a year before ChatGbt. And the second thing is, I highlighted is all engineers. This is a real email. I was like, I want Co-Pilot, I want it now, and I want it for everybody. What was amazing about this was, one, and I talked to the GitHub team this morning. Thomas did give it to me, and all of my engineers, which is thousands, the GitHub team did not know. That's number one. And then two, what's funny is, in the summer of 2022, he came to Toronto where I live, and he messaged me and said, can I meet up with you? I was pretty sure he was trying to get me to pay for Co-Pilot, and we were using it for free. So we are now a happy paying customer. Back then, I was like, I'm going to keep using this for free as long as I can. And so I'll show you some stats on what the adoption was. But why did we end up choosing Co-Pilot? There are competitor products. I meet with lots of startups. You're watching Twitter, X, seeing newsletters. You see lots of AI tools coming out, especially for code completion and for engineering productivity. For us, it was a few reasons. The first was, we did not want to increase our trust circle. So at Shopify, we think about, who has access to our data? Our code is in GitHub. Because our code is in GitHub, we are not increasing the trust circle to include Co-Pilot. That makes it very easy for us to say, let's try it. That's number one. Number two is GitHub and OpenAI and Microsoft, like all these partners that are working together, are innovating very, very quickly. You saw Thomas this morning talking about all the things that they are launching. We've been lucky to be early access on some of those. And the curve of innovation is what you have to make a bet on, not on what Co-Pilot has today. You can look at other tools and say, oh, we can try this one, we can try that one, we can try that one. Sure, you should. You should try them. But the bet we're making is that the curve of what GitHub is doing will enable us to have all of those features very quickly. And so, you know, I have a great relationship with the GitHub team. We always talk to them and say, hey, this company is doing this. Are you guys bringing it to GitHub Co-Pilot? And I think there's one other interesting thing people don't maybe necessarily think about, which is sometimes in doing the deep dive on some of these tools, Co-Pilot has decided not to offer something because it actually doesn't work. So, for example, right now we talk about generalized models, right, when you use Co-Pilot and autocomplete, everyone's got the same Co-Pilot, right, we all have the same Co-Pilot. And Thomas talked about this morning that potentially you might want to train Co-Pilot on your own repo and then ask it questions. What's interesting is, in a lot of cases, by using a specific model on your repo, it might actually perform worse than the generic model that's trained on all the open source repos. And so, in having those conversations with a partner like GitHub allows you to then make the trade-off is like, do you want to do this? It's going to be expensive to train your own model and it might perform worse. Versus, talking to startup who might say, this is what you need. That's one. Another one is, you know, talking about having Co-Pilot for PR reviews, right? In early investigations with GitHub, they noticed that the automatic descriptions and commenting that comes back from a PR review that someone might submit, might actually just cause them to do work that is not actually that important. And now you're adding developer toil without maybe getting the benefit. And so again, working with a partner like that allows you to think through the second and third or consequences versus just saying, let's use this AI tool, let's give them our data and they may or may not be in your best interest through that. Co-Pilot adoption at Shopify, we have done a lot. Right after that December 2021 email, in January, we launched Co-Pilot with all of our engineers. And a year later, Co-Pilot for Business is basically the way of saying that we started paying for it a year later in March. We started using some of the tools. You'll notice some of the words here are what was announced today because we've been in early access with GitHub for a while. Right, the ability to have Co-Pilot docs, Co-Pilot chat on GitHub.com, Co-Pilot chat in VS Code, all of the things that you saw demoed this morning. We've been playing with them. So what's interesting is you're starting to see which ones developers are gaining confidence in and how their perceptions are changing. But then also, which ones are not yet have product market fit at least in Shopify as they get better. And so we'll talk through some of those. But there's a lot happening here that shows you the pace of innovation that's happening and the panacea, which is making sure that your engineers are more productive. So how should we think about this? Right, a lot of this was, this actually came up this morning with folks. How should you measure developer productivity? I don't know if they're ask McKinsey. I'm kidding. Definitely do not ask McKinsey. That's insane. Right, they're consulting company. What you should be thinking about instead is what matters for your developer community. And if you look at the spectrum of art and science, there are people on both sides. Right, there's a science. Let's track 50 different metrics and let's see if our engineering team is doing well. And then there's the art. Are you building the right thing for your customers? Shopify tends to be on the art side. We really believe that software development and building products is more like path finding. Right, if you ever see like lightning strike, you see like the ground and you have lightning at the top and it's trying to find a path to the ground. That's what we think. Software development is it's not a straight line. It is trying to find a path. You're going forward. You're deleting code. You're prototyping. You're starting over. You start walking towards horizon and you decide you want to go that way. That is not something that can be numerically assessed easily. And so when I talk to companies and a lot of CTOs call me and they say, well, how did you decide to use co-pilot? I'll talk through some of the metrics we do track and we did find interesting. But one of them is happiness. So it's interesting. I don't know what could be some of these things, but we have found that in doing the quantitative analysis of co-pilot is not going to tell you the whole picture. But doing a qualitative analysis might. And again, I talked to lots of companies. Some of them, and again, we don't track that many things. I have like three or four things that we track here. And again, I'll tell you the reasons we track those. But I talked to lots of companies, attract the full Dora space. They use the different tools. I have a list of I think 50 different startups that want to connect to your GitHub and give you statistics. I'm not saying that's bad. I'm just saying it might be interesting data, but it might not be telling you the whole picture. One story I do want to tell you, I talked to a company that had I think 3000 engineers. And they track 50 different metrics. They deployed co-pilot. And the CTO called me and said, we've been running it now for, I think it was two or three months. They saw nothing. No change. I was like, okay. But he said one thing. And I said, okay, so nothing in the numbers. But did you run a developer happiness survey? Did you do any qualitative? Oh, yeah, yeah. We did it like a, we asked our engineers. And they off the charts. We're saying they're a happier at their job and happier using co-pilot. So again, we see something similar. It doesn't have to be in the quantitative measurements. It might just be in the qualitative measurements. And when I asked that CTO again 3000 engineers, they're paying for co-pilot, are you going to keep it? He said, of course, I'm going to keep it. Because the engineers are happier. That is like, you know, happy engineers. Let's turn over more happy at their job, getting towards the solutions faster. Like all those things matter. So that, and that CTO still rolled out co-pilot, even though they saw zero on the quantitative. Now, I would call bullshit, I think, on the no quantitative change. But that's what he saw and still ended up rolling it out anyway. So what do we look at? So we look at two or three different things across our ecosystem. Of course, we look at happiness. That is one. We do a developer happiness survey. We want to make sure that we are getting a lot of the qualitative feedback. And we do see high correlation with co-pilot and happiness. But we look at some other things. We look at PRs. And again, we're not looking at PRs per week to compare person A and person B and saying, oh, that person has 20 per week and that has 30. Like, it's more about, how do we unblock somebody if they're stuck? And so again, we see some correlation with, hey, this person is stuck. They may not have a PR this week. Let's talk to them and see what's going on. We see high correlation with pairing. I love Thomas' whole pair programming. I'm a huge pair programming fan. We believe and feel like co-pilot is a pair programmer for your engineers. And should be treated like a pair programmer. A smart co-pilot, funny name. A smart co-pilot to work with you while you're going through these problems. That hopefully lets you stay in flow longer than you would have been if you had to go and leave the window and go search something else. One of the amazing things that's happening in you saw it again this morning's demo is the ability to have like a co-pilot chat now in VS code. So you're, you know, I used to work with a lot of engineers who would cut and paste code, go to chat, GBT, come back. And now you're leaving and going back and forth in these workflows. Having these things in line, highlighting code and then asking co-pilot questions. All that is now just in flow. And again, staying in flow is the name of the game because we know it takes, you know, 20 or 30 minutes to get back into flow. And pair programming really helps you stay in flow. So we look at pair programming. We see some correlation there. Of course, I'd mentioned happiness. And we actually really think that this makes a big difference. Even if you are not seeing anything on the qualitative, which again, I'll call a little bit of bullshit on that one. For us, what we do see is those engineers who use co-pilot do tend to have some correlation with impact. And I think the key thing to think about in correlation, and I talked about correlation with PRs, correlation with pair programming, correlation with co-pilot is its correlation. You don't know which direction the arrow flows. So for example, I cannot tell if co-pilot makes good engineers or if good engineers use co-pilot. But I do know that they're correlated. So I don't know if I care which way the arrow goes. Right? Because if good engineers want to use co-pilot, great. If co-pilot makes good engineers, great. Right? If good engineers ship more PRs, great. If more PRs makes good engineers, great. Like it doesn't matter to me which way the arrow goes. But again, I'm not trying to be too scientific. For us, it is an art form to try to think and dissect these types of results. And that's how folks should think about it in their company. Right? I want to have my engineers focus on the thing that matters more for them. And so in pair programming, and again, co-pilot, you don't want to look at lines of code. Because in a lot of times, it's less code that you want. Right? And I mentioned that maybe I should be ashamed that I have the largest Ruby code base in the world instead of actually saying this is something to celebrate. I would like less code. I would like to subtract more code. I would like my system to be more simple. It allows me to reason about it better. And as these tools get better, I want co-pilot to say delete this module, delete this code. Here's a simpler way of approaching this solution. That's what we want to see. And that's why the pair programming paradigm is actually much better metaphor, I think, because the idea is that you are pairing with somebody. There's one thing that we did try. In pair programming, if folks have done it, it's two engineers, one machine, two keyboards, two mice, and they work together, is I did try to hack together via the accessibility mode, this idea of voice co-pilot. So the idea that I could just talk to co-pilot, and you would talk back to me while I coded instead of actually doing it by the typing interface. I couldn't get it to work exactly, but I think that's coming as well, where you actually could have like a more natural interface than typing. So I'm going to share some survey data, and again, this is the qualitative data that we had at Shopify about how often folks were using co-pilot, what they felt about it, how useful they found it. And again, you're seeing some pretty high scores for some of the products that have been out in our case, like we've been using co-pilot for almost two years now. And when we talk about co-pilot, we talk about the autocomplete of co-pilot, the generalized model autocomplete. And again, those models are getting better, we heard it was gpt3.5, and then gpt3.5 Turbo, we saw that open AI launched gpt4 Turbo, which hopefully is fast enough for autocomplete, and we'll start seeing these get even better. And as you go down from that, you see some of the other products that gpt1 launch, some of them announced today that yet don't have product market for Shopify, but again, we just launched them. Right? Github CLI, github co-pilot for github co-pilot chat, co-pilot chat and VS code, github co-pilot for docs. All these things we think will have great adoption as they are find product market fit inside Shopify. Again, still early days for us, but you can start seeing that the numbers are actually quite high, right? 70% useful, 75% use it all the time. Some numbers, we do have lots and lots of folks using co-pilot. It's funny, when I talk to different teams, I feel like, let's say it's about 70% of engineering is using co-pilot. I think that number is low. I talked to other engineering leaders, they think that numbers high. It depends on what your goals are. Right? In my mind, we are seeing that there's a slight correlation between using co-pilot and having great impact. Again, don't know which way the arrow goes, but it's interesting to see why people don't use co-pilot, and I'll talk about that in a bit. We have lots of engineers who have used it for six months or more. I think one of the interesting things there is acceptance rate. Again, I have lots of debates with people. It's 26% to 25%, 15%, 30%, are those high numbers or low numbers? So for us, I believe those are high numbers. What that's saying is almost one in four times, we are accepting the suggestion from co-pilot. Now, you could take the pessimistic view and be like, wow, so three out of four times, you're not taking the suggestion, unlike sure. But what happens in some cases is you don't take the suggestion, but you take the idea. Oh, I see where you're going, and then you don't take the suggestion, but then you write something similar or you get an idea that it's now prompted you towards. In this morning's keynote, we heard, I don't want to start with the blank page. And this is exactly where co-pilot excels, because you can write a comment, and it can start writing some code for you. Even if it's wrong, it starts you off in the right direction. Or even, by the way, in the wrong direction, but that is something for you to get started with in an edit. And then, of course, that Shopify Ruby is the number one language we use there, and you can see that that's the most popular language that GitHub co-pilot gives us suggestions for. But we do see varying rates. We do see from 15% to 30% acceptance rate across our repos, depending on the language. Again, more survey data, a qualitative. We do see things becoming, as people get more comfortable, more and more folks using it over time. And again, this is engineers getting more comfortable, as more IDE's get supported by GitHub as well. We can start tracking this data better. And we are starting to see more and more of the senior engineers also picking up co-pilot, where at the beginning, I think they felt it was like a beginner tool. So, why don't we go through again some more qualitative data, and just specifically here to show you the difference between what we saw at the mid-year and at the end of the year. So, what's interesting is, as people, when you start asking these questions, we can see that there are people's perceptions of what co-pilot can do change. So, for example, people originally felt like I'm going to get more productivity. It's going to help me with repetitive code. It's going to help me writing tests. And over time, you can see how they started changing, say, actually, you know what? I'm actually getting productivity boosts. It's actually smartly completing my code. And so, even their perception of using the models, and as we all know, behind the scenes, the models are getting better. It's learning. But the people are also learning. Co-pilot is not something that you drop into your organization, and it's just going to be something that people adopt, and they don't change. They're going to change with co-pilot. We see this with any new tool. What's the Martian McLuhan line, versus you shape the tools and the tool shapes you? That's what happens with co-pilot. You start working with co-pilot as your pair programmer. And again, you start seeing how people change their perception of what they thought they were going to learn with co-pilot, with what they actually do. And what's interesting here is you start seeing how people are actually thinking through how they want to use co-pilot. Maybe they're going to start something in a new language that they never used before, because they're now feeling like they can get over that barrier. At Shopify, for example, our systems programming language is rust. And we are seeing people who start using rust more because they're now not afraid because they've got a co-pilot to come along with them. Again, more survey data. And you're seeing again what people are feeling like they're going to be helped with in the mid-year, and where they end up. So people do feel that are appreciating it. It is a tool that saves time. And if you're saving time and again replacing tasks, there is a cost benefit to that, although it's hard again to quantify. And again, CTOs and CFOs, we want to quantify the results of the co-pilot or any AI tools, and it's tough to do. Unlike a cost like your salary, it's very easy to quantify. It's hard to say, oh, well, these people are happier and got to the solution faster, even though they produced potentially less code. Or they were not daunted by starting a new project in a language they didn't know because they had co-pilot helping them. So again, trying to justify the cost only quantitatively might be super tough. And maybe not something you actually want to do because it might take you away from actually having your eyes on the prize, which is using it for a while, changes the way developers interact with the tool. One of the things I like to say is it's kind of like surgery. You don't want to leave halfway. You want to deploy it for, I would say a quarter or two before you actually get a feel for whether it's working or not. And again, in many organizations, I just talked to somebody this morning who was thinking about co-pilot and how to roll it out in their trial group, and whether to look at those metrics and then determine should we roll it out for the whole company. And again, only looking at quantitative, it might be hard because they want to figure out well, how many lines of code did it write or what was the acceptance rate or how much faster, what's our velocity? Again, looking at the art and science line, it may be hard to see. But looking at the qualitative, it does tend to show up pretty quickly. And of course, you know, in some of these things, you see that, you know, is co-pilot going to generate my boilerplate code for me? Yeah, the answer is yes. And what we find with engineers is they're more able, especially the more senior you get, they're more able to spend their time in the more complicated parts of the program. And that actually our value added versus the boilerplate code and the repetitive code or the tests that they feel like might not be where they want to spend most of their time. Again, here's some data on co-pilot chat data. This is actually, again, things that were announced this morning. We're seeing some interesting data coming through and how our engineers use the various parts of co-pilot to stay in flow. And the comments mentioned this morning, you know, co-pilot workspaces, which again is a way to keep you in the flow of your development cycles. So you're not reaching for other tools, not going outside of co-pilot, not going to chat to BT on the web, not going to, I mean, I don't know if people are going to stack overflow anymore, not going to those tools. Because what's happening is you're trying to integrate everything into one single IDE. And what's interesting about that is, again, staying in flow, that's what pair programming is about. That's what co-pilot is trying to do. We're trying to help, it's trying to help you improve productivity. And again, you can see what's what people are thinking about in terms of the things that they want from co-pilot. Again, on the qualitative side, you want to make sure that you are thinking through the entire solution. And if you're not actually, if you're an engineering organization that is not doing a developer happiness survey or not doing any kind of qualitative analysis, you're probably missing out on a plethora of feedback that could be helping you drive your engineering org forward. So, no, somebody clapped, I don't know. One clap for that one. Okay, cool. So now co-pilot does have a learning curve. When I made me that, it is not something you drop and it's like, take it easy, everyone. We just put this new tool in. Hope it is working. Like, that's not how I would launch anything. I talked, you know, at the beginning of the presentation, really about bringing AI into your workflow across the company, your customers, and your employees in a way such that this is one of a suite of tools that your team might actually adopt. It's a powerful one. And you saw in that, you know, that tweet I showed where after sales and marketing engineering is one that comes up there. But there are things that you have to work differently around with co-pilot. The way you write comments completely changes with co-pilot. So, anybody who's used co-pilot, they know that by writing comments is how you prompt the machine. And of course, we saw today that you can now use co-pilot chat to generate boilerplate code as well. But what is the main difference is how you write comments. And you're not just writing comments again for you. You are, of course, writing them for you. Or the future you who's going to be forgetting about this code in two weeks. But it's also for co-pilot. And co-pilot is going to make a guess as to what code you're trying to write. And it does change the interaction model. You have to get used to the autocomplete because what happens is you're going to have the grade out text and you're going to either accept it or not accept it. Again, what I have seen is even when I don't accept the code, it's now priming me with ideas that I might want to use to then actually write something else. So the acceptance rate may or not be an actual indication of how well it's working because potentially it's priming me for some other type of development that I might want to do. It is not perfect. Co-pilot makes mistakes. We saw one in the demo this morning. Humans make mistakes also. Your pair programmer makes mistakes. You will make mistakes. You still have to be a good engineer to work with co-pilot. So for the Doomsday or about AI out there saying, hey, co-pilot or these tools are going to replace engineers, that is not true. It's going to make you more effective. It is going to replace some of your tasks, but it's not going to replace you. And the reason for that is because you're going to still have to understand what the code is. That's still going to happen. And yeah, you can try to write some things but as soon as you try to modify, you want to make sure you are still getting a feel for what is being developed. And again, this is true of a pair programmer also. You shouldn't sit with somebody and they write a bunch of code and you don't understand it. You should understand the code that's being written. And by the way, it will make mistakes just like a human. Now the tools are going to get better and better, but it is a workflow change. And I think what's interesting about it is keeping you in flow is the key. Here's an example of one I just literally did this last week when I was writing this deck where I was like, let me just open up co-pilot and actually just write sample code. And as you can see, I just created an array and right away co-pilot, I actually should have done a better job of highlighting what co-pilot wrote and what I wrote. But co-pilot wrote a loop, a for loop at the beginning, which just iterated through my array from 1 to 100, 0 to 100, and instead of using the array length. And you can see right away, that's just poor code because if I change the length of the array, the for loop will not work as intended. But now what's interesting is the comments that I wrote, I was prompting co-pilot. So I said iterate through the array. It wrote the right code. It actually used the array length. And then I said print the array. It wrote the right code. Use the array length. But the first loop is wrong. Right now there's nothing there that's telling me except good engineering practices. That potentially, it's making a mistake. It's not thinking through the problem in a way that's going to be maintainable later. This will probably just work. And then someday someone will come in and be like this, the array is to short, change it, and now everything will not work. So again, this is a very simple example. You can open up your own ID and try this. But the idea is the models will get better and you will get better at identifying things like this. This is a super spicy topic because at Shopify we hire lots and lots of engineers. And I talk to a lot of engineering leaders and they say, well, my interview process now is all screwed because they're just going to use co-pilot. And now I can't tell if they're a good engineer or if co-pilot is a good engineer. And I was like, well, if co-pilot can write your interview questions, maybe your interview questions are dumb. Because yes, co-pilot is going to get better and people are going to get smarter and people are going to become more effective. And we ran this trial at Shopify where we, I mean, right now we allow candidates to use co-pilot. We tell them about it in the process and we say, you can use co-pilot. And it does not be co-pilot. It can be any of the AI productivity tools because we believe that actually we get to more interesting questions by using these tools. Right? That's one reason. The other reason is your interview process should be the almost the same as your job. So if you use co-pilot at work, use AI assistance at work, then you want to allow your candidates to use the same tools because then you can tell whether they would be good at this job. It's weird to be like, we can't use co-pilot in the interview, but then you will use it at work. I'm like, well, are you testing the same things then? And so for us, we do use it at work. We allow it. We don't discount you if you don't want to use it. Although I'm sure there's going to be some future state where if I ask candidate, are you going to use co-pilot and they say, no, I'm going to be like, why? Because it's weird. It's like, here's a bunch of numbers. Add them up. Do you want to use a calculator? No. Why? Like, I'm just interested. Now right now, it's not really fair because they might be coming from a company that they don't have co-pilot. And you're like, I don't want you to learn how to use co-pilot in the interview. So it's fair. But over time, it's going to be weird that you don't use an AI assistant in your coding interview. And one interesting anecdote is, I do a lot of interviews shadowing. I talked to lots of engineers and I shadow the interviewer because I want to evaluate the interviewer. And I will turn off my camera and mic and just watch candidates. And whenever there's a candidate who's not using co-pilot, what I've noticed, because I tend to try to do the same questions as the candidates to kind of see if the questions are, you know, ones I think would help evaluate an engineer correctly, is every time I use, I have a candidate that's not using co-pilot and I am, I tend to finish the question twice as fast. So if the candidate has 90 minutes to do a question, I tend to finish it in 45 minutes. I leave the call and send my solution to the interviewer to be marked just like the candidate. But what's funny is an old, you know, rusty programmer like me can actually quickly get up to speed finish these problems in a way that is very, very fast. So just some ideas around legal. This is the number one thing I hear from engineering leaders. How should I think about the legal aspect of code being generated by open source repost by co-pilot. Now here are two press releases. I didn't get a chance to put the third one in, which is open AI has a thing called copyright shield, right, which is the idea that they're going to help indemnify you. One of those is for Microsoft, one of those posts, one's from Google. And basically what they're saying is, we will indemnify you if you get sued for using our tools. That's interesting. I don't think that's the thing that you want to rely upon. I think the real answer is to work with your legal team early and often to think through how you want to deploy these types of tools in your company. So imagine your designers want to use mid-journey, same idea. You should be talking to your team about how to use these things versus just saying at the end of the process. By the way, we're going to use this tool. Help me get this through procurement legal. Like that's not how to work with your team. All right, so what have we seen so far at Shopify? I mentioned 70% of the engineers. We are at about 26% of the code completion. We are almost at 1 million lines of code written by co-pilot. Pretty amazing. Still a small amount of code in Shopify sense, but still amazing that that co-pilot is being that productive for us that we have this amount of code in our repos already. You can see there are almost 700,000 acceptances by engineers of the co-pilot suggestion. The reason that those numbers are different is because a co-pilot suggestion is one thing, but it might generate like 10 lines of code. That's not even including all the prompting that you get that might make you land in a direction that is fruitful, but you don't accept the suggestion in which case it won't even show up in these stats. It won't show up in the lines of code. It won't show up in the acceptance rate. That's probably higher than that. Cool. And then of course, happy engineers, which is something we should all strive for. Lastly, it's not all roses. There are some things that co-pilot we hear from people who don't use co-pilot. It gets in the way. It feels like I'm cheating, which is an interesting one. We hear that from candidates. I don't trust it. We do see some of it around too slow. That will get fixed or the suggestions are not that good. These will get better over time. But again, just for your organizational purview, you can start thinking through why an engineer may or may not want to use co-pilot. In summary, reach for AI early and often. And if you're using GitHub, it's a no-banner use co-pilot. Thank you very much. You
